{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bca49fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99867d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST_Polygon('~/Developer/datasets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c13fadad",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-48-fc8449dc0960>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-fc8449dc0960>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1 2 3 4\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1 2 3 4\n",
    "5 6 7 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "240fc9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Polygon(datasets.MNIST):\n",
    "    \n",
    "    def __init__(self, path, train=True, download=False, transform = None):\n",
    "        super().__init__(root=path, train=train, download=download)\n",
    "        \n",
    "        data = self.data.view(-1, 784)\n",
    "        data = list(data.unbind())\n",
    "        data = [torch.arange(784)[(x > 0.8)] for x in data]\n",
    "        lengths = [len(x) for x in data]\n",
    "        max_length = max(lengths)\n",
    "        data = [torch.Tensor(list(x) + (351 - len(x)) * [0]) for x in data]\n",
    "        data = torch.stack(data).contiguous()\n",
    "        self.data = torch.reshape(data, (len(data) , 1, 351))\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        return x, y\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def raw_folder(self):\n",
    "        return os.path.join(self.root, 'MNIST', 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self):\n",
    "        return os.path.join(self.root, 'MNIST', 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d54673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = MNIST_Polygon('~/Developer/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "broken-router",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[127., 128., 129., 130., 131., 154., 155., 156., 157., 158., 159., 181.,\n",
       "          182., 183., 184., 185., 186., 187., 188., 189., 207., 208., 209., 210.,\n",
       "          211., 212., 213., 214., 215., 216., 217., 235., 236., 237., 238., 239.,\n",
       "          240., 241., 242., 243., 244., 245., 262., 263., 264., 265., 266., 267.,\n",
       "          268., 269., 270., 271., 272., 273., 289., 290., 291., 292., 293., 294.,\n",
       "          295., 296., 297., 300., 301., 302., 316., 317., 318., 319., 320., 321.,\n",
       "          328., 329., 330., 343., 344., 345., 346., 347., 348., 349., 356., 357.,\n",
       "          358., 371., 372., 373., 374., 384., 385., 386., 399., 400., 401., 412.,\n",
       "          413., 414., 426., 427., 428., 429., 440., 441., 442., 454., 455., 456.,\n",
       "          457., 466., 467., 468., 469., 470., 482., 483., 484., 493., 494., 495.,\n",
       "          496., 497., 510., 511., 512., 520., 521., 522., 523., 538., 539., 540.,\n",
       "          547., 548., 549., 550., 566., 567., 568., 569., 570., 571., 572., 573.,\n",
       "          574., 575., 576., 577., 578., 594., 595., 596., 597., 598., 599., 600.,\n",
       "          601., 602., 603., 604., 622., 623., 624., 625., 626., 627., 628., 629.,\n",
       "          630., 651., 652., 653., 654., 655., 656., 657.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.]]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f1cbccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "x, y = s[1]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef176337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe973667250>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = torch.zeros(784)\n",
    "img[x.long()] = 1.0\n",
    "img = img.view(28, 28)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "789d32c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "847113fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST_Polygon\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /Users/davemeijdam/Developer/datasets\n",
       "    Split: Train"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af04f621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.,  5.,  5.,  6.,  6.,  6.,  6.,  6.,  7.,  7.,  7.,  7.,  7.,  7.,\n",
       "         8.,  8.,  8.,  8.,  8.,  9.,  9.,  9.,  9.,  9., 10., 10., 10., 10.,\n",
       "        10., 10., 11., 11., 11., 11., 11., 11., 11., 12., 12., 12., 12., 12.,\n",
       "        12., 12., 13., 13., 13., 13., 13., 13., 13., 13., 13., 14., 14., 14.,\n",
       "        14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 14., 15., 15.,\n",
       "        15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15., 15.,\n",
       "        15., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 16., 17., 17.,\n",
       "        17., 18., 18., 18., 19., 19., 19., 20., 20., 20., 21., 21., 21., 22.,\n",
       "        22., 22., 23., 23., 23., 24., 24., 24.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x // 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2686d155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 21., 22.,  4.,  5., 20., 21., 22.,  4.,  5., 19., 20., 21., 22.,\n",
       "         4.,  5., 19., 20., 21.,  4.,  5., 19., 20., 21.,  3.,  4.,  5., 19.,\n",
       "        20., 21.,  3.,  4.,  5., 18., 19., 20., 21.,  3.,  4.,  5., 18., 19.,\n",
       "        20., 21.,  3.,  4.,  5., 15., 16., 17., 18., 19., 20.,  3.,  4.,  5.,\n",
       "         9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20.,  3.,  4.,\n",
       "         5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18.,\n",
       "        19.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 17., 18., 19., 17., 18.,\n",
       "        19., 17., 18., 19., 17., 18., 19., 17., 18., 19., 17., 18., 19., 17.,\n",
       "        18., 19., 17., 18., 19., 17., 18., 19.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x % 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7c266d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "de2a3d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([127., 128., 129., 130., 131., 154., 155., 156., 157., 158., 159., 181.,\n",
       "        182., 183., 184., 185., 186., 187., 188., 189., 207., 208., 209., 210.,\n",
       "        211., 212., 213., 214., 215., 216., 217., 235., 236., 237., 238., 239.,\n",
       "        240., 241., 242., 243., 244., 245., 262., 263., 264., 265., 266., 267.,\n",
       "        268., 269., 270., 271., 272., 273., 289., 290., 291., 292., 293., 294.,\n",
       "        295., 296., 297., 300., 301., 302., 316., 317., 318., 319., 320., 321.,\n",
       "        328., 329., 330., 343., 344., 345., 346., 347., 348., 349., 356., 357.,\n",
       "        358., 371., 372., 373., 374., 384., 385., 386., 399., 400., 401., 412.,\n",
       "        413., 414., 426., 427., 428., 429., 440., 441., 442., 454., 455., 456.,\n",
       "        457., 466., 467., 468., 469., 470., 482., 483., 484., 493., 494., 495.,\n",
       "        496., 497., 510., 511., 512., 520., 521., 522., 523., 538., 539., 540.,\n",
       "        547., 548., 549., 550., 566., 567., 568., 569., 570., 571., 572., 573.,\n",
       "        574., 575., 576., 577., 578., 594., 595., 596., 597., 598., 599., 600.,\n",
       "        601., 602., 603., 604., 622., 623., 624., 625., 626., 627., 628., 629.,\n",
       "        630., 651., 652., 653., 654., 655., 656., 657.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(list(x) + 608 * [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aaaa060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4., 15.],\n",
       "        [ 4., 16.],\n",
       "        [ 4., 17.],\n",
       "        [ 4., 18.],\n",
       "        [ 4., 19.],\n",
       "        [ 5., 14.],\n",
       "        [ 5., 15.],\n",
       "        [ 5., 16.],\n",
       "        [ 5., 17.],\n",
       "        [ 5., 18.],\n",
       "        [ 5., 19.],\n",
       "        [ 6., 13.],\n",
       "        [ 6., 14.],\n",
       "        [ 6., 15.],\n",
       "        [ 6., 16.],\n",
       "        [ 6., 17.],\n",
       "        [ 6., 18.],\n",
       "        [ 6., 19.],\n",
       "        [ 6., 20.],\n",
       "        [ 6., 21.],\n",
       "        [ 7., 11.],\n",
       "        [ 7., 12.],\n",
       "        [ 7., 13.],\n",
       "        [ 7., 14.],\n",
       "        [ 7., 15.],\n",
       "        [ 7., 16.],\n",
       "        [ 7., 17.],\n",
       "        [ 7., 18.],\n",
       "        [ 7., 19.],\n",
       "        [ 7., 20.],\n",
       "        [ 7., 21.],\n",
       "        [ 8., 11.],\n",
       "        [ 8., 12.],\n",
       "        [ 8., 13.],\n",
       "        [ 8., 14.],\n",
       "        [ 8., 15.],\n",
       "        [ 8., 16.],\n",
       "        [ 8., 17.],\n",
       "        [ 8., 18.],\n",
       "        [ 8., 19.],\n",
       "        [ 8., 20.],\n",
       "        [ 8., 21.],\n",
       "        [ 9., 10.],\n",
       "        [ 9., 11.],\n",
       "        [ 9., 12.],\n",
       "        [ 9., 13.],\n",
       "        [ 9., 14.],\n",
       "        [ 9., 15.],\n",
       "        [ 9., 16.],\n",
       "        [ 9., 17.],\n",
       "        [ 9., 18.],\n",
       "        [ 9., 19.],\n",
       "        [ 9., 20.],\n",
       "        [ 9., 21.],\n",
       "        [10.,  9.],\n",
       "        [10., 10.],\n",
       "        [10., 11.],\n",
       "        [10., 12.],\n",
       "        [10., 13.],\n",
       "        [10., 14.],\n",
       "        [10., 15.],\n",
       "        [10., 16.],\n",
       "        [10., 17.],\n",
       "        [10., 20.],\n",
       "        [10., 21.],\n",
       "        [10., 22.],\n",
       "        [11.,  8.],\n",
       "        [11.,  9.],\n",
       "        [11., 10.],\n",
       "        [11., 11.],\n",
       "        [11., 12.],\n",
       "        [11., 13.],\n",
       "        [11., 20.],\n",
       "        [11., 21.],\n",
       "        [11., 22.],\n",
       "        [12.,  7.],\n",
       "        [12.,  8.],\n",
       "        [12.,  9.],\n",
       "        [12., 10.],\n",
       "        [12., 11.],\n",
       "        [12., 12.],\n",
       "        [12., 13.],\n",
       "        [12., 20.],\n",
       "        [12., 21.],\n",
       "        [12., 22.],\n",
       "        [13.,  7.],\n",
       "        [13.,  8.],\n",
       "        [13.,  9.],\n",
       "        [13., 10.],\n",
       "        [13., 20.],\n",
       "        [13., 21.],\n",
       "        [13., 22.],\n",
       "        [14.,  7.],\n",
       "        [14.,  8.],\n",
       "        [14.,  9.],\n",
       "        [14., 20.],\n",
       "        [14., 21.],\n",
       "        [14., 22.],\n",
       "        [15.,  6.],\n",
       "        [15.,  7.],\n",
       "        [15.,  8.],\n",
       "        [15.,  9.],\n",
       "        [15., 20.],\n",
       "        [15., 21.],\n",
       "        [15., 22.],\n",
       "        [16.,  6.],\n",
       "        [16.,  7.],\n",
       "        [16.,  8.],\n",
       "        [16.,  9.],\n",
       "        [16., 18.],\n",
       "        [16., 19.],\n",
       "        [16., 20.],\n",
       "        [16., 21.],\n",
       "        [16., 22.],\n",
       "        [17.,  6.],\n",
       "        [17.,  7.],\n",
       "        [17.,  8.],\n",
       "        [17., 17.],\n",
       "        [17., 18.],\n",
       "        [17., 19.],\n",
       "        [17., 20.],\n",
       "        [17., 21.],\n",
       "        [18.,  6.],\n",
       "        [18.,  7.],\n",
       "        [18.,  8.],\n",
       "        [18., 16.],\n",
       "        [18., 17.],\n",
       "        [18., 18.],\n",
       "        [18., 19.],\n",
       "        [19.,  6.],\n",
       "        [19.,  7.],\n",
       "        [19.,  8.],\n",
       "        [19., 15.],\n",
       "        [19., 16.],\n",
       "        [19., 17.],\n",
       "        [19., 18.],\n",
       "        [20.,  6.],\n",
       "        [20.,  7.],\n",
       "        [20.,  8.],\n",
       "        [20.,  9.],\n",
       "        [20., 10.],\n",
       "        [20., 11.],\n",
       "        [20., 12.],\n",
       "        [20., 13.],\n",
       "        [20., 14.],\n",
       "        [20., 15.],\n",
       "        [20., 16.],\n",
       "        [20., 17.],\n",
       "        [20., 18.],\n",
       "        [21.,  6.],\n",
       "        [21.,  7.],\n",
       "        [21.,  8.],\n",
       "        [21.,  9.],\n",
       "        [21., 10.],\n",
       "        [21., 11.],\n",
       "        [21., 12.],\n",
       "        [21., 13.],\n",
       "        [21., 14.],\n",
       "        [21., 15.],\n",
       "        [21., 16.],\n",
       "        [22.,  6.],\n",
       "        [22.,  7.],\n",
       "        [22.,  8.],\n",
       "        [22.,  9.],\n",
       "        [22., 10.],\n",
       "        [22., 11.],\n",
       "        [22., 12.],\n",
       "        [22., 13.],\n",
       "        [22., 14.],\n",
       "        [23.,  7.],\n",
       "        [23.,  8.],\n",
       "        [23.,  9.],\n",
       "        [23., 10.],\n",
       "        [23., 11.],\n",
       "        [23., 12.],\n",
       "        [23., 13.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = []\n",
    "for a in x:\n",
    "    z.append((int(a // 28), int(a % 28)))\n",
    "    \n",
    "torch.Tensor(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "862a51ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 32, 347]             192\n",
      "       BatchNorm1d-2              [-1, 32, 347]              64\n",
      "              ReLU-3              [-1, 32, 347]               0\n",
      "            Conv1d-4              [-1, 64, 343]          10,304\n",
      "       BatchNorm1d-5              [-1, 64, 343]             128\n",
      "              ReLU-6              [-1, 64, 343]               0\n",
      "         MaxPool1d-7              [-1, 64, 171]               0\n",
      "           Dropout-8              [-1, 64, 171]               0\n",
      "            Linear-9                  [-1, 128]       1,400,960\n",
      "             ReLU-10                  [-1, 128]               0\n",
      "          Dropout-11                  [-1, 128]               0\n",
      "           Linear-12                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 1,412,938\n",
      "Trainable params: 1,412,938\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.93\n",
      "Params size (MB): 5.39\n",
      "Estimated Total Size (MB): 6.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "epochs = 14\n",
    "lr = 0.001\n",
    "gamma = 0.7\n",
    "log_interval = 10\n",
    "dry_run = False\n",
    "save_model = False\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, 5),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(32, 64, 5),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(10944, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "        \n",
    "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "#         self.dropout1 = nn.Dropout(0.25)\n",
    "#         self.dropout2 = nn.Dropout(0.5)\n",
    "#         self.fc1 = nn.Linear(9216, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x, 2)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.fc2(x)\n",
    "\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.linear(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output\n",
    "summary(Net(), (1,351))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abef5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()), end=\"\\r\")\n",
    "            if dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cf545e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.782754\n",
      "Test set: Average loss: 1.4702, Accuracy: 4573/10000 (45.7%)\n",
      "\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.642554\n",
      "Test set: Average loss: 0.7444, Accuracy: 7432/10000 (74.3%)\n",
      "\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.658525\n",
      "Test set: Average loss: 0.8952, Accuracy: 7039/10000 (70.4%)\n",
      "\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.562247\n",
      "Test set: Average loss: 1.3609, Accuracy: 6126/10000 (61.3%)\n",
      "\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.452403\n",
      "Test set: Average loss: 0.7598, Accuracy: 7524/10000 (75.2%)\n",
      "\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.373842\n",
      "Test set: Average loss: 0.5971, Accuracy: 7978/10000 (79.8%)\n",
      "\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.366090\n",
      "Test set: Average loss: 0.5972, Accuracy: 8007/10000 (80.1%)\n",
      "\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.403855\n",
      "Test set: Average loss: 0.6202, Accuracy: 7938/10000 (79.4%)\n",
      "\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.352463\n",
      "Test set: Average loss: 0.5014, Accuracy: 8287/10000 (82.9%)\n",
      "\n",
      "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.414556\n",
      "Test set: Average loss: 0.4903, Accuracy: 8340/10000 (83.4%)\n",
      "\n",
      "Train Epoch: 11 [59520/60000 (99%)]\tLoss: 0.296463\n",
      "Test set: Average loss: 0.4619, Accuracy: 8458/10000 (84.6%)\n",
      "\n",
      "Train Epoch: 12 [59520/60000 (99%)]\tLoss: 0.382670\n",
      "Test set: Average loss: 0.4542, Accuracy: 8487/10000 (84.9%)\n",
      "\n",
      "Train Epoch: 13 [59520/60000 (99%)]\tLoss: 0.406606\n",
      "Test set: Average loss: 0.4515, Accuracy: 8495/10000 (85.0%)\n",
      "\n",
      "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.393710\n",
      "Test set: Average loss: 0.4512, Accuracy: 8506/10000 (85.1%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "\n",
    "    device = \"cpu\"\n",
    "\n",
    "    train_kwargs = {'batch_size': batch_size}\n",
    "    test_kwargs = {'batch_size': test_batch_size}\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = MNIST_Polygon('~/Developer/datasets', train=True, download=True, transform=transform)\n",
    "    dataset2 = MNIST_Polygon('~/Developer/datasets', train=False, transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b9f2cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "dataset1 = MNIST_Polygon('~/Developer/datasets', train=True, download=True, transform=transform)\n",
    "dataset2 = MNIST_Polygon('~/Developer/datasets', train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "earlier-gilbert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1, 311])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-convenience",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
